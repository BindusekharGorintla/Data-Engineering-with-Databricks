{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921472d1-f550-408f-9a29-0000a67143b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08c269dc-4727-40ac-9646-3469aa5bb655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Appendix - Ingesting XML Files with Databricks\n",
    "### Extra material, not part of a live teach.\n",
    "In this demonstration we will go over how to ingest XML files and store them as Bronze Delta tables.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this lesson, you should be able to:\n",
    "\n",
    "- Use the `CREATE TABLE AS SELECT` (CTAS) statement with the `read_files()` function to ingest XML files into a Delta table, including any rescued data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08fd89ca-0aa2-4217-a0c3-44bb832b899d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "  - In the drop-down, select **More**.\n",
    "\n",
    "  - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f508c78-1254-4a2b-a6cd-1ad48821d0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this notebook.\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course in the lab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad0437a3-9e8b-4e61-a7fb-c321f9343386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5a8cd8e-9b93-441c-9b2b-956c044da0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run the cell below to view your default catalog and schema. Notice that your default catalog is **dbacademy** and your default schema is your unique **labuser** schema.\n",
    "\n",
    "**NOTE:** The default catalog and schema are pre-configured for you to avoid the need to specify the three-level name for when writing your tables (i.e., catalog.schema.table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38a1daa5-3b1d-4e2c-bc06-087f5b9a2181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog(), current_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e44e721-7e7d-4449-a967-020bbe151290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. CTAS with `read_files()` for Ingesting XML Files\n",
    "\n",
    "In this section, we'll explore how to ingest raw XML (Extensible Markup Language) files from cloud storage into a Delta table. XML files are structured text files that use custom tags to organize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d04158df-8d32-4c3e-9f51-b5c7a966309d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In the code below, we dynamically pass variables to `read_files()` since each user has a unique username within the Vocareum environment. This is done using the `DA` object created during classroom setup. \n",
    "\n",
    "For example, the expression:\n",
    "\n",
    "`DA.paths_working_dir || '/xml_demo_files/example_1_data.xml'`\n",
    "\n",
    "evaluates to the string:\n",
    "\n",
    "`/Volumes/dbacademy/ops/<username>/xml_demo_files/example_1_data.xml`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1be0e868-fb00-4409-b6e3-164af8533b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B1. View the XML File\n",
    "\n",
    "1. Follow the steps below to view your XML file in your course volume: **dbacademy.ops.labuser**\n",
    "\n",
    "   a. In the left navigation bar, select the catalog icon:  ![Catalog Icon](../Includes/images/catalog_icon.png)\n",
    "\n",
    "   b. Expand the **dbacademy** catalog.\n",
    "\n",
    "   c. Expand the **ops** schema.\n",
    "\n",
    "   d. Expand **Volumes**. You should see a volume with your **labuser** name, which contains the source data to ingest.\n",
    "\n",
    "   e. Expand your **labuser** volume. This volume contains several subdirectories. We will use the **xml_demo_files** directory.\n",
    "\n",
    "   f. Expand the **xml_demo_files** subdirectory. It should contain the file: **example_1_data.xml**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f75860be-bc7d-499a-9067-d388f7f238ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since XML files can be difficult to work with, let's start this demonstration by looking at the **example_1_data.xml** XML file:\n",
    "\n",
    "```\n",
    "  <books>\n",
    "    <book id=\"222\">\n",
    "      <author>Corets, Eva</author>\n",
    "      <title>Maeve Ascendant</title>\n",
    "    </book>\n",
    "    <book id=\"333\">\n",
    "      <author>Corets, Eva</author>\n",
    "      <title>Oberon's Legacy</title>\n",
    "    </book>\n",
    "  </books>\n",
    "```\n",
    "\n",
    "This XML contains:\n",
    "- The Top level element `<books>`. This is the root element. It acts as a container for all the `<book>` elements.\n",
    "- Each `<book>` element represents a single book and includes:\n",
    "  - The `id` attribute which uniquely identifies the book.\n",
    "  - The `<author>` child element containing the name of the author. \n",
    "  - The `<title>` child element containing the title of the book. \n",
    "\n",
    "\n",
    "Our goal in ingesting this XML file is to flatten it into a tabular form so we can store it as a Delta table. We'll define the following columns:\n",
    "\n",
    "- **book_id** (extracted from the `id` attribute)\n",
    "- **author** (extracted from the `<author>` element text)\n",
    "- **title** (extracted from the `<title>` element text)\n",
    "\n",
    "Each `<book>` element will be treated as a row. To achieve this, we set `rowTag => 'book'` when using `read_files()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed97bb17-bbcf-4883-ad37-72a50ca86d4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B2. Using the `read_files()` Function to Ingest XML\n",
    "\n",
    "The code in the next cell creates a structured table using a `CREATE TABLE AS SELECT` (CTAS) statement along with the `read_files()` function.\n",
    "\n",
    "We are using the following options with the `read_files()` function:\n",
    "\n",
    "1. `format => \"xml\"` – Specifies that the input data is in XML format.  \n",
    "2. `rowTag => \"book\"` – Identifies the repeating XML element (`<book>`) that defines individual rows.  \n",
    "3. `schema => '_id INT, author STRING, title STRING'` – Enforces a schema for known fields in the XML.  \n",
    "4. `rescuedDataColumn => '_rescued_data'` – Captures any malformed or unexpected fields that do not match the schema into a separate column for later inspection.\n",
    "\n",
    "This example demonstrates how to parse structured XML using schema enforcement while preserving problematic or unknown data for troubleshooting. For brevity, we skip the actual troubleshooting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc41a3bb-5260-443c-8c7c-56eb473ae32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Run the following cell to read in this XML file. The following query also brings in a `_rescued_data` column. Note that this column will return `NULL` because this XML file is made up of clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c35577ba-f34e-4c0c-b539-9de68e04681e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM read_files(\n",
    "       DA.paths_working_dir || '/xml_demo_files/example_1_data.xml',\n",
    "       format => \"xml\",\n",
    "       rowTag => 'book',\n",
    "       schema => '''\n",
    "            _id INT, \n",
    "            author STRING, \n",
    "            title STRING\n",
    "          ''',\n",
    "       rescueddatacolumn => '_rescued_data'\n",
    "     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b48764c-e295-42d8-a31d-130cf2432598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. We can also change the `rowTag` parameter to `\"books\"` to produce a different flattening of the XML file. \n",
    "\n",
    "    In this case, we omit the explicit schema definition and allow schema inference. The resulting output is a single row containing a nested array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd2677e2-856f-473f-a6c7-8665adf6ace1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM read_files(\n",
    "       DA.paths_working_dir || '/xml_demo_files/example_1_data.xml',\n",
    "       format => \"xml\",\n",
    "       rowTag => 'books',\n",
    "       rescueddatacolumn => '_rescued_data'\n",
    "     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37be62e4-9564-43ea-954c-768c647881a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Let's finish by writing to Delta table based on the first schema presented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7319a818-7bc3-4dfd-9c92-50bc03a122be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Drop the table if it exists for demonstration purposes\n",
    "DROP TABLE IF EXISTS books_bronze_xml;\n",
    "\n",
    "\n",
    "-- Create the Delta table\n",
    "CREATE TABLE books_bronze_xml \n",
    "AS\n",
    "SELECT\n",
    "  _id AS book_id,\n",
    "  * EXCEPT (_id),\n",
    "  current_timestamp AS ingestion_timestamp,\n",
    "  _metadata.file_name AS source_file\n",
    "FROM read_files(\n",
    "       DA.paths_working_dir || '/xml_demo_files/example_1_data.xml',\n",
    "       format => \"xml\",\n",
    "       rowTag => 'book',\n",
    "       schema => '''\n",
    "            _id INT, \n",
    "            author STRING, \n",
    "            title STRING\n",
    "          ''',\n",
    "       rescuedDataColumn => '_rescued_data'\n",
    "     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47abe878-38c8-408f-b655-357faa2e4705",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Inspect the newly created **bronze** table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b639f8da-275a-43df-98dd-39b43f3c83e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM books_bronze_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08320d45-cf22-4ea3-8fb5-9154f6da45b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- View the datatypes of the columns \n",
    "DESCRIBE books_bronze_xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec32d701-b525-45d7-a627-92da4632b4b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "A1 - Ingesting XML Files with Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}